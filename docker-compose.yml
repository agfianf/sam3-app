version: '3.8'

services:
  # Backend - SAM3 FastAPI Application
  backend:
    build:
      context: ./apps/api-inference
      dockerfile: Dockerfile
    # images: sam3-be
    container_name: sam3-backend
    command: uv run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    volumes:
      - ./apps/api-inference/src:/code/src  # Mount source for hot-reload
      - huggingface_cache:/root/.cache/huggingface  # Cache model downloads
    env_file:
      - ./apps/api-inference/.env
    restart: unless-stopped
    networks:
      - sam3-network
    # Uncomment for GPU support (requires nvidia-docker)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Frontend - React Annotation Platform
  frontend:
    build:
      context: ./apps/web
      dockerfile: Dockerfile
      target: development
    # images: sam3-fe
    container_name: sam3-frontend
    ports:
      - "5173:5173"
    volumes:
      - ./apps/web:/app
      - /app/node_modules
    env_file:
      - ./apps/web/.env
    depends_on:
      - backend
    networks:
      - sam3-network
    command: npm run dev -- --host 0.0.0.0

  # Frontend Production (uncomment for production)
  # frontend-prod:
  #   build:
  #     context: ./frontend
  #     dockerfile: Dockerfile
  #   container_name: sam3-frontend-prod
  #   ports:
  #     - "3000:80"
  #   depends_on:
  #     - backend
  #   networks:
  #     - sam3-network
  #   restart: unless-stopped

volumes:
  huggingface_cache:
    driver: local

networks:
  sam3-network:
    driver: bridge
